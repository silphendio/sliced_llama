# sliced_llama
Simple LLM inference server
